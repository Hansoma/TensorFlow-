## 卷积神经网络

### 卷积
卷及神经网络通过卷积核在图片上滑动, 遍历像素点, 提取图片特征.

扫描时对于边缘像素点有两种方法:
* padding: 
    1. SAME: 入长/步长 (向上取整)
    2. VALID(不完全填充): (入长-核长+1)/步长 (向上取整)

*TensorFlow* 中有用于计算卷积的函数:
```
tf.nn.conv2d(输入描述: eg. [batch, 5(分辨率), 5(分辨率), 1(通道数)],
            卷积核描述: eg. [3(行列分辨率), 3(行列分辨率), 1(通道数), 16(核个数)],
            核滑动步长: eg. [1, 1(行步长), 1(列步长), 1],
            padding = 'VALID',
            )
```

### 池化
池化可以进一步减少特征数量, **最大值池化**可以提取图片纹理, **均值池化**可以保留背景特征.

*TensorFlow* 同样给出了这两种池化的计算方法.
```
pool = tf.nn.max_pool()
pool = tf.nn.avg_pool()
参数如下:
(
    输入描述: eg.[batch, 28(行列分辨率), 28(行列分辨率), 6(通道数)],
    池化核描述(仅大小): eg.[1, 2(行列分辨率), 2(行列分辨率), 1],
    池化核滑动步长: eg.[1, 2(行步长), 2(列步长), 1],
    padding = "SAME",
)
```

训练过程中为了避免过多参数, 将一部分神经元按照一定的概率从神经网络中暂时舍弃, 使用时被舍弃的神经元恢复链接. *TensorFlow* 提供了 *dropout* 函数来进行暂时舍弃. dropout 可以减小过拟合的问题, 加快训练速度.
```
tf.nn.dropout(上层输出, 暂时舍弃的概率)
```
卷积神经网络的一般步骤为:
卷积, 激活, 池化, 喂入全连接网络. 

