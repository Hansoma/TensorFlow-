# 神经网络的进一步优化

4.4.1 节将介绍通过指数衰减的方法设置梯度下降算法中的学习率. 通过指数衰减的设置的学习率既可以让模型在前期快速接近最优解, 又可以让模型在后期不会出现太大波动.

4.4.2 节将介绍过拟合的问题, 在训练复杂的神经网络时, 过拟合是十分常见的问题.

## 4.4.1 学习率的设置

学习率既不宜过大也不宜过小. 

为了解决学习率的设置问题, *TensorFlow* 提供了一种更加灵活的设置学习率的方法--指数衰减法, *tf.train.exponential_delay* 实现了指数衰减的学习率. 通过这个函数, 可以先使用较大的学习率来得到一个比较优的解, 然后随着迭代继续逐步减小学习率. 


*tf.train.exponential_decay()* 实现了下面的算法
```
decayed_learning_rate = \
    learning_rate * decay_rate ^ (gobal_step / decay_steps)

'''
decayed_learning_rate 为每一轮优化时使用的学习率,
learning_rate 为事先设计的初始学习率.
decay_rate 为衰减系数,
decay_steps 为衰减速度,

tf.train.exponential_decay()中可选参数:
staircase, 默认为False, 这时学习率的变化趋势如曲线,
如果设为True, global_step/decay_steps会被化为整数.
'''
```

下面的代码给出了具体用法:

```
global_step = tf.Variable(0)

# 通过exponential_dacay函数生成学习率
learning_rate = tf.train.exponential_decay(
    0.1, global_step, 100, 0.96, staircase=True)

# 使用指数衰减的学习率. 在minimize函数中传入global_step将自动更新global_step参数,
# 从而使得学习率也得到相应更新
learning_step = tf.train.GradientDescentOptimizer(learning_rate)\
                .minimize(...my_loss..., global_step=global_step)
```

上面这段代码设定了初始学习率为0.1, 因为staircase=True所以每一百轮后学习率乘以0.96,
一般来说, 初始学习率, 衰减系数, 衰减速度都是根据经验设置的.
而且损失函数下降的速度和迭代结束后总损失的大小没有必然联系,
因此不能通过前几轮损失函数下降的速率来比较不同神经速率的效果.

## 4.4.2 过拟合问题

4.2 和 4.3 节重点讲解了如何在训练数据上优化一个给定的损失函数, 然而在真实的应用中, 我们并不是让模型尽量模拟训练数据的行为, **而是希望通过训练出来的模型对未知的数据给出判断**.

过拟合指的是, 当一个模型过于复杂时, 它可以很好地记忆每一个训练数据中随机产生的噪音部分而忘记了要去学习数据中通用的趋势. 

为了避免过拟合问题, 常采用的方法是正则化.
```
# coding=utf-8
import tensorflow as tf

"""
下面的代码给出了一个简单的带L2的正则化的损失函数定义
"""
"""
w = tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))
y = tf.matmul(x, w)


loss = tf.reduce_mean(tf.square(y_ - y)) +
        tf.contrib.layers.l2regularrizer(lambda)(w)

"""

"""
下面的代码给出了L1和L2正则化的使用样例
"""
weights = tf.constant([[1.0, -2.0], [-3.0, 4.0]])
with tf.Session() as sess:
    """0.5为正则化的权重"""
    # (|1| + |-2| + |-3| + |4|)*0.5 = 5.0
    print(sess.run(tf.contrib.layers.l1_regularizer(.5)(weights)))
    # (1^2 + (-2)^2 + (-3) ^2 + 4^2)/2 * 0.5 = 7.5
    print(sess.run(tf.contrib.layers.l2_regularizer(.5)(weights)))
```

在简单的神经网络中,这样的方式就可以很好的计算带有正则化的损失函数了.
但当神经网络的参数增多之后, 这样的方式:
1.可能导致loss的定义很长.
2.网络结构复杂之后, 定义网络结构的部分和计算损失函数的部分可能不在同一个函数中,这样通过变量这种方式计算损失函数就不方便了.

我们做出如下改进:

```
#coding=utf-8
"""
为了解决上个demo中提出的问题,可以使用tensorflow中提供的collection.
集合可以在一张计算图中保存一组实体.(比如张量)
"""

import tensorflow as tf

# 获取一层神经网络边上的权重, 并将这个权重的L2正则化损失加入名称为'losses'的集合中.
def get_weights(shape, lambd):
    # 生成一个变量
    var = tf.Variable(tf.random_normal((shape), dtype=tf.float32))
    # add_to_collection函数将这个新生成变量的L2正则化损失项加入集合
    # 这个函数的第一个参数'losses'是集合的名字, 第二个参数是要加入这个集合的内容
    tf.add_to_collection(
        'losses', tf.contrib.layers.l2_regularizer(lambd)(var))
    return var

x = tf.placeholder(tf.float32, shape=(None, 2))
y_ = tf.placeholder(tf.float32, shape=(None, 1))
batch_size = 8
# 定义了每一层网络中的节点的个数
layer_dimension = [2, 10, 10, 10, 1]
# 神经网络的层数
n_layers = len(layer_dimension)

# 这个变量维护前向传播时最深层的节点,最开始就是输入层
cur_layer = x
# 当前层的节点个数
in_dimension = layer_dimension[0]

# 通过一个循环来生成5层全连接额神经网络结构
for i in range(1, n_layers):
    # layer_dimension[i]为下一层的节点个数
    out_dimension = layer_dimension[i]
    # 生成当前层中权重的变量, 并将这个变量的L2正则化损失加入计算图上的集合
    weight = get_weights([in_dimension, out_dimension], 0.001)
    bias = tf.Variable(tf.constant(0.1, shape=[out_dimension]))
    # 使用ReLU激活
    cur_layer = tf.nn.relu(tf.matmul(cur_layer, weight) + bias)
    # 进入下一层之前将下一层的节点数更新为当前层的节点数
    in_dimension = layer_dimension[i]

# 在定义神经网络前向传播的同时已经将所有的L2正则化损失加入了图上的集合,
# 这里只需要计算刻画模型在训练数据上表现的损失函数
mse_loss = tf.reduce_mean(y_ - cur_layer)

# 将均方误差损失函数加入损失集合
tf.add_to_collection('losses', mse_loss)

# get_collection返回一个列表, 这个列表是所有这个集合中的元素.
# 在这个样例中, 这些元素就是损失函数的不同部分, 将它们加起来可以得到最终的损失函数.
loss = tf.add_n(tf.get_collection('losses'))
```

## 4.4.3 滑动平均模型
在采用随机梯度下降算法训练神经网络时, 使用滑动平均模型可以在很多应用中一定程度上提高最终模型在测试数据上的表现.

Tensorflow中提供 `tf.train.ExponentialMovingAverage` 来实现滑动平均模型.

在初始化 *ExponentialMovingAverage* 时, 需要一个衰减率(*decay*).这个衰减率将用于控制模型的更新速度.

*ExponentialMovingAverage* 对每一个变量会维护一个影子变量(*shadow*), 这个影子变量的初始值就是相应变量的初始值, 而每次运行变量更新时, 影子变量的值会更新为:
```
shadow_variable = decay x shadow_variable + (1-decay) x variable
```
其中, *shadow_variable* 为影子变量, *variable* 为待更新的变量, *decay* 为衰减率. 从公式上可以看出, *decay* 决定了模型的更新速度, 其值越大, 模型越趋于稳定, 在实际应用中, decay一般会被设成非常接近1的数(比如0.999或是0.9999).

为了使模型在前期可以更新的更快, *ExponentialMovingAverage* 还提供了一个  *num_updates* 参数来动态设置 *decay* 的大小. 这个参数的具体公式详见书本P91.

下面一段代码解释了 *ExponentialMovingAverage* 是如何使用的:

```
#coding=utf-8
import tensorflow as tf

# 定义一个变量用于计算滑动平均, 这个变量的初始值是0. 注意这里手动指定了变量的类型为float32
# 因为所有需要计算滑动平均的变量必须是实数型.
v1 = tf.Variable(0, dtype=tf.float32)
# 这里step 变量模拟神经网络中的迭代轮数, 可以用于动态控制衰减率.
step = tf.Variable(0, trainable=False)

# 定义一个滑动平均的类(class). 初始化时给定衰减率0.99, 和控制衰减率的变量step.
ema = tf.train.ExponentialMovingAverage(0.99, step)
# 定义一个更新滑动平均的操作. 这里需要给定一个列表, 每次执行这个操作时, 这个列表中的变量都会被更新.
maintain_averages_op = ema.apply([v1])

with tf.Session() as sess:
    # 初始化所有变量
    init_op = tf.global_variables_initializer()
    sess.run(init_op)

    # 通过ema.average(v1)获取滑动平均之后变量的取值. 在初始化之后,变量v1的值和v1的滑动平均都是0.
    print(sess.run([v1, ema.average(v1)]))      # 输出[0.0, 0.0]

    #更新变量v1的值到5
    sess.run(tf.assign(v1, 5))
    # 更新v1的滑动平均值. 衰减率为min{0.99, (1+step)/(10+step)=0.1} = 0.1,
    # 所以v1的滑动平均值会被更新为0.1x0+0.95x5=4.5
    sess.run(maintain_averages_op)
    print(sess.run([v1, ema.average(v1)]))      #输出[5.0, 4.5]

    #更新step的值为1000
    sess.run(tf.assign(step, 10000))
    # 更新v1的值为10
    sess.run(tf.assign(v1, 10))
    # 更新v1的滑动平均值. 衰减率为min{0.99, (1+step)/(10+step) 约= 0.999} = 0.99
    # 所以v1的滑动平均会被更新为0.99x4.5+0.01x10=4.555
    sess.run(maintain_averages_op)
    print(sess.run(v1, ema.average(v1)))

    # 再次更新滑动平均值, 得到新的滑动平均值为0.99x4.555+0.01x10=4.60945
    sess.run(maintain_averages_op)
    print(sess.run([v1, ema.average(v1)]))
    # 输出[10.0, 4.609499]



```