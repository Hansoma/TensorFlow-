# TensorFlow 运行模型--会话

*TensorFlow* 使用会话的模式一般有**两种**, 一种明确调用会话, 另一种通过*python*的上下文机制.

* ## 明确调用
```
sess = tf.Session()
sess.run(...)
sess.close()
```

* ## 上下文
```
with tf.Session() as sess:
    sess.run(...)
# 上下文退出时, 资源也自动释放了
```

使用上下文可以在上下文退出时, 自动释放资源, 同时, 也解决了在异常退出时
资源释放的问题.

3.1节介绍过, TensorFlow会自动生成一个默认的计算图, 如果没有特殊指定, 
运算会自动加入这个计算图中. *TensorFlow* 的会话也有类似机制, 但是不会自动生成默认会话, 
需要手动指定. 当默认会话指定之后, 可以通过`tf.Tensor.eval`函数来计算一个张量的取值.
```
sess = tf.Session()
with sess.as_default():
    sess.run(result)
```
下面代码也可以完成相同的功能
```
sess = tf.Session()
# 以下两句具有相同的功能
print(sess.run(result))
print(sess.eval(session=sess))
```
*TensorFlow* 也提供一种交互式环境类似的方法, `tf.InteractiveSession`, 
使用这个函数会自动将生成的会话当作默认会话.

```
sess = tf.InteractiveSession()
print(result.eval())
sess.close()
```
这个方法可以省去将产生的会话注册为默认会话的过程.

ConfigProto可以对session进行配置,类似线程数或是GPU分配策略
常用参数:

* `allow_soft_placement` 
一般设置为True, 在GPU无法进行运算时将运算转到CPU上.

* `log_device_placement` 
 记录log方便调试,生产过程中置为false减少日志量

下面给出一段通过config配置会话的过程
```
config = tf.ConfigProto(allow_soft_placement=True,log_device_placement=True)
sess1 = tf.InteractiveSession(config=config)
sess2 = tf.InteractiveSession(config=config)
```

