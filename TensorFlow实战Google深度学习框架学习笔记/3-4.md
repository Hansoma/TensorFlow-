# TensorFlow 实现神经网络

## 3.4.1 简介
[TensorFlow游乐场](http://playground.tensorflow.org)

在机器学习中, 所有用于描述实体的数字的组合就是一个实体的**特征向量(feature vector)**.

目前主流的神经网络结构都是分层结构:

* ### 第一层是输入层:
>输入层代表特征向量中每一个特征的取值
>
>同一层之间的节点不会相互连接, 只和下一层连接

* ### 最后一层是输出层:
>输出层得到最终的计算结果.
>
>在二分类问题中, 输出层往往只包含一个节点, 而在这个节点会输出一个实数值.
>通过这个值和一个事先设定的阀值, 可以得到最后的分类结果.
>一般可以认为当输出值离阀值越远时得到的答案越可靠.
>

* ### 在输入层和输出层之间是隐藏层:
>一般一个神经网络的隐藏层越多, 这个神经网络就越深.

## 综上所述使用神经网络解决**分类问题**可以分为以下四个步骤:
1. 提取问题中的实体的特征作为神经网络的输入.
2. 定义神经网络的结构, 并定义如何从神经网络的输入得到输出. 这个过程就叫神经网络的前向传播算法.
3. 通过参数训练来调整神经网络中的参数取值, 这就是训练神经网络的过程.
4. 使用训练好的神经网络来预测未知的数据.这个过程和步骤2中的前向传播算法一致, 不再赘述.

## 3.4.2 前向传播算法简介
本书介绍的是最简单的全连接网络结构的前向传播算法, 并将展示如何通过TensorFlow实现这个算法.

首先介绍一下**神经元**, 神经元是构成一个神经网络的最小单元, 一个神经元有多个输出和一个输入.

神经网络的结构说的就是不同的神经元之间的连接结构. 一个最简单的神经元结构的输出就是所有输入的加权和. 而不同的输入的权重就是神经元的参数. 神经网络的优化过程就是神经元中参数取值的过程.

本书之后的章节将统一使用节点来代指神经网络中的神经元.

前向传播算法可以表示为矩阵乘法.

以下是 *TensorFlow* 实现神经网络前向传播算法过程的代码.
```
a = tf.matmul(x, w1)
y = tf.matmul(a, w2)
```
`tf.matmul` 实现了矩阵乘法的功能.

## 3.4.3 神经网络参数和 *TensorFlow* 变量

在 *TensorFlow* 中, 变量 *(tf.Variable)* 的作用就是保存和更新神经网络中的参数.
这个变量也需要制定初始值.

下面的代码给出了一种在 *TensorFlow* 中声明一个2x3的矩阵的方法.
```
# 矩阵中元素是均值为0, 标准差为2的随机数.
weights = tf.Varible(tf.random_normal([2, 3], stddev=2))
````
*TensorFlow* 目前支持的所有随机数产生器以及常数生成函数见书本P54

* ### TensorFlow随机数生成函数
>
>tf.random_normal() # 正态分布
>
>tf.truncated_normal() # 正态分布,但是标准差超过2会被重新随机
>
>tf.random_uniform() # 均匀分布
>
>tf.constant() # 产生一个给定值的常量

* ### TensorFlow常数生成函数
>
>tf.zeros() # 生成全是0的数组
>
>tf.ones() # 生成全是1的数组
>
>tf.fill() # 产生一个全部为给定数字的数组
>
>tf.constant() # 产生一个给定值的常量

下面的样例介绍了如何通过变量实现神经网络参数, 并实现前向传播的过程.
```
# 声明w1,w2两个变量,还通过seed参数设定了随机种子
# 这样可以保证每次运行得到的结果是一样的
w1 = tf.Variable(tf.random_normal((2,3), stddev=1, seed=1))
w2 = tf.Variable(tf.random_normal((3,1), stddev=1, seed=1))

# 暂时将输入的特征向量定义为一个常量,注意这里的x是一个1x2的矩阵
x = tf.constant([[0.7, 0.9]])

# 通过前面所述的前向传播算法获得神经网络的输出
a = tf.matmul(x, w1)
y = tf.matmul(a, w2)

sess = tf.Session()
# 与之前不同,不可以直接sess.run(y)来获取y的值
# 因为还要将w1, w2进行初始化

"""
#coding=utf-8
import tensorflow as tf
w1, w2并没有被真正的运行,所以还需要通过initializer来进行初始化
特别的:对所有变量进行初始化
init_op = tf.global_variables_initializer()
sess.run(init_op)
"""

sess.run(w1.initializer) # 初始化w1
sess.run(w2.initializer) # 初始化w2

# 输出[]
print("*************Result of x**********************")
print(sess.run(x))
print("*************Result of w1***********************")
print(sess.run(w1))
print("*************Result of a*************************")
print(sess.run(a))
print("*************Result of w2***********************")
print(sess.run(w2))
print("*************Result of y************************")
print(sess.run(y))
"""
tf.glabal_variables()可以取出当前计算图中的所有变量
"""
print("*****************Result of all variables**********************")
print(sess.run(tf.global_variables()))

sess.close()
```

在上面的样例中, 将w1和w2两个变量分别进行了初始化, 而 *TensorFlow* 提供了另外一种更为简便的方法.详见下面的代码:
```
init_op = tf.global_variables_initializer()
sess.run(init_op)
```
通过声明函数中的 *trainable* 参数,来进行区分需要优化的参数
如果声明为 *True* ,则可以通过 *tf.trainable_variables* 函数得到所有的需要优化的参数. 
 *tensorflow* 会将 *GraphKeys.TRAINABLE_VARIABLES* 集合中的所有变量作默认的优化对象

变量与张量的关系: *tf.Variable* 是一个运算, 这个运算的输出结果是一个张量. **张量**,**维度**和**类型**是变量的最重要属性, 变量的类型是不可变的,一个变量在构建之后,它的类型就不能再改变了, 维度在程序中是可以改变的. 需要通过参数设置 *validate_shape=False* ,例如下面这段代码:
```
w1 = tf.Variable(tf.random_normal([2, 3], stddev=1), name="w1")
w2 = tf.Variable(tf.random_normal([2, 2], stddev=1), name="w2")

# 下面的这段会报错:维度不匹配
# tf.assign(w1, w2)

# 改成这一句可以成功执行:
# 注意: 这种用法在实践中比较少见
tf.assign(w1, w2, validate_shape=False)
```

## 3.4.4 通过 *TensorFlow* 训练神经网络模型

* ### 监督学习
>监督学习最重要的思想就是, 在已知答案的标注数据集上, 模型给出的预测结果要尽量接近真实答案. 
>
>在神经网络优化算法中, 最常用的方法是 **反向传播算法(backpropagation)**.
>
>反向传播算法实现了一个 **迭代** 的过程. 
>
>* 首先,在每次迭代的开始,需要选取一小部分训练数据, 这一小部分数据叫做一个 *batch*.
>
>* 然后这个 *batch* 的样例会通过前向传播算法得到神经网络模型的预测结果. 因为训练数据都是有正确答案标注的, 所以可以计算出当前神经网络模型的预测答案和正确答案之间的差距.
>
>* 最后, 基于预测值和真实值之间的差距, 反向传播算法会相应更新神经网络参数的取值, 使得这个 *batch* 上神经网络模型的预测结果和真实答案更加接近. 

* ### placeholder
由于迭代的轮数很多, 所以 *TensorFlow* 引入 *placeholder* 机制, 相当于定义一个位置, 这个位置中的数据在程序运行时再指定, 这样在程序中就不需要生成大量的常量来提供输入数据, 而只需要将数据通过 *placeholder* 传入 *TensorFlow* 计算图. 在 *placeholder* 中数据的维度信息可以根据提供的数据推导得出, 所以不一定需要给出. 下面给出通过 *placeholder* 实现前向传播算法的代码.
```
#coding=utf-8

import tensorflow as tf

"""
通过placeholder实现前向传播算法
placeholder的类型也是不可以改变的
"""
w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))
w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))

# 定义placeholder作为存放数据的地方,这里的维度不一定要定义
# 但如果维度是确定的,第=定义维度可以降低出错的概率

x = tf.placeholder(tf.float32, shape=(1, 2), name="input")
a = tf.matmul(x, w1)
y = tf.matmul(a, w2)

sess = tf.Session()
init_op = tf.global_variables_initializer()
sess.run(init_op)

# 一定要给出feed_dict, 为palceholder设定取值
print(sess.run(y, feed_dict={x: [[0.7, 0.9]]}))
```
*feed_dict* 中给出每个用得到的 *placeholder* 的值, 如果某个需要的 *placeholder* 没有被指定取值, 那么程序运行时将会报错. 

当 *x* 的 *shape* 改变时, 相应的 *feed_dic* 也需要发生改变. 

* ### 损失函数

在得到一个 *batch* 的前向传播结果之后, 需要定义一个**损失函数**来刻画当前预测值和真实答案之间的差距, 然后通过**反向传播算法**来调整神经网络的参数取值, 使得差距可以被缩小. 下面代码定义了一个简单的损失函数:
```
#使用sigmoid函数讲y转换为0~1之间的数值.转换后的y代表预测是正样本的概率,1-y代表预测是负样本的概率
y = tf.sigmoid(y)
#定义损失函数来刻画预测值与真实值的差距
cross_entropy = -tf.reduce_mean(
    y_ * tf.log(tf.clip_by_value(y, le -10, 1.0))
    + (1-y)*tf.log(tf.clip_by_value(1-y, le-10, 1.0)))
#定义学习效率
learning_rate = 0.001
#定义反向传播算法来优化神经网络的参数
train_step = \
    tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)
``` 

## 3.4.5 完整的神经网络样例程序

直接贴上代码, 可以在 *PycharmProjects/TFdemo01/tfdemo07.py* 中查阅.
```
#coding=utf-8
"""
完整的神经网络样例程序
"""
import tensorflow as tf

#numpy是一个科学计算的工具包,这里通过numpy工具包生成模拟数据集
from numpy.random import RandomState

#定义训练数据batch的大小
batch_size = 8

#定义神经网络参数,这里沿用之前的设置
w1 = tf.Variable(tf.random_normal((2,3), stddev=1, seed=1))
w2 = tf.Variable(tf.random_normal((3,1), stddev=1, seed=1))

#在shape的一个维度上使用None可以方便使用不同的batch大小.
#在训练需要把数据分成比较小的batch,但是在测试时,可以一次性使用全部数据.
#当数据集比较小时,这样比较方便测试,但数据集比较大时,将大量数据放入一个batch可能造成内存溢出
x = tf.placeholder(tf.float32, shape=(None, 2), name='x_input')
y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y_input')

#定义神经网络前向传播的过程
a = tf.matmul(x, w1)
y = tf.matmul(a, w2)

#定义损失函数和前向传播算法
#使用sigmoid函数讲y转换为0~1之间的数值.转换后的y代表预测是正样本的概率,1-y代表预测是负样本的概率
y = tf.sigmoid(y)
#定义损失函数来刻画预测值与真实值的差距
cross_entropy = -tf.reduce_mean(
    y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))
    + (1-y)*tf.log(tf.clip_by_value(1-y, 1e-10, 1.0)))
#定义学习效率
learning_rate = 0.001
#定义反向传播算法来优化神经网络的参数
train_step = \
    tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)

#通过随机数生成一个模拟数据集
rdm = RandomState(1)
dataset_size = 128
X = rdm.rand(dataset_size, 2)
#定义规则来给出样本的标签.这里所有的x1+x2<1都被认为是正样本(比如零件合格),
#而其他为负样本(比如零件不合格)
#这里用0表示负样本,用1表示正样本,大部分解决神经网络的问题都会用0和1的表示方法
Y = [[int(x1+x2 < 1)] for (x1, x2) in X]

#创建一个会话来运行tensorflow程序:
with tf.Session() as sess:
    init_op =  tf.global_variables_initializer()
    #初始化变量
    sess.run(init_op)

    print(sess.run(w1))
    print(sess.run(w2))

    """
    打印训练之前的神经网络参数值
    
    """
    #设定训练的轮数
    STEPS = 5000
    for i in range(STEPS):
        #每次选取batch_size个样本进行训练
        start = (i * batch_size) % dataset_size
        end = min(start+batch_size, dataset_size)

        #通过选取的样本训练神经网络并更新参数
        sess.run(train_step,
                 feed_dict = {x: X[start:end], y_:Y[start:end]})
        if i%1000 == 0:
            #每隔一段时间计算在所有数据上的交叉熵并输出
            total_cross_entropy = sess.run(
                cross_entropy, feed_dict={x: X, y_: Y})
            print("After {} training step(s), cross entropy on all data is {}"
                  .format(i, total_cross_entropy))

    print(sess.run(w1))
    print(sess.run(w2))
```
